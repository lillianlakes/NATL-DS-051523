{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Cost-Functions-and-Solutions-To-the-Optimization-Problem\" data-toc-modified-id=\"Cost-Functions-and-Solutions-To-the-Optimization-Problem-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Cost Functions and Solutions To the Optimization Problem</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Bad-News\" data-toc-modified-id=\"The-Bad-News-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>The Bad News</a></span></li><li><span><a href=\"#The-Good-News\" data-toc-modified-id=\"The-Good-News-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>The Good News</a></span><ul class=\"toc-item\"><li><span><a href=\"#ðŸ§ -Knowledge-Check\" data-toc-modified-id=\"ðŸ§ -Knowledge-Check-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>ðŸ§  Knowledge Check</a></span></li><li><span><a href=\"#More-Log-Loss-Resources\" data-toc-modified-id=\"More-Log-Loss-Resources-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>More Log-Loss Resources</a></span></li></ul></li></ul></li><li><span><a href=\"#Digging-Deeper-into-Logistic-Regression\" data-toc-modified-id=\"Digging-Deeper-into-Logistic-Regression-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Digging Deeper into Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preparing-Data\" data-toc-modified-id=\"Preparing-Data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Preparing Data</a></span></li><li><span><a href=\"#Train-Logistic-Regression\" data-toc-modified-id=\"Train-Logistic-Regression-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Train Logistic Regression</a></span></li><li><span><a href=\"#Interpreting-Logistic-Regression-Coefficients\" data-toc-modified-id=\"Interpreting-Logistic-Regression-Coefficients-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Interpreting Logistic Regression Coefficients</a></span></li></ul></li><li><span><a href=\"#Putting-It-All-Together:-Training-Logistic-Regression\" data-toc-modified-id=\"Putting-It-All-Together:-Training-Logistic-Regression-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Putting It All Together: Training Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-and-Explore-Data\" data-toc-modified-id=\"Load-and-Explore-Data-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Load and Explore Data</a></span></li><li><span><a href=\"#Create-and-Train-Logistic-Regression-Model\" data-toc-modified-id=\"Create-and-Train-Logistic-Regression-Model-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Create and Train Logistic Regression Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Optional:-Evaluate-the-Model-with-Cross-Validation\" data-toc-modified-id=\"Optional:-Evaluate-the-Model-with-Cross-Validation-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Optional: Evaluate the Model with Cross-Validation</a></span></li><li><span><a href=\"#Optional:-Rinse-and-Repeat---Multiple-Models\" data-toc-modified-id=\"Optional:-Rinse-and-Repeat---Multiple-Models-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Optional: Rinse and Repeat - Multiple Models</a></span></li></ul></li><li><span><a href=\"#Final-Evaluation\" data-toc-modified-id=\"Final-Evaluation-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Final Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-Set\" data-toc-modified-id=\"Training-Set-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Training Set</a></span></li><li><span><a href=\"#Testing-Set\" data-toc-modified-id=\"Testing-Set-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Testing Set</a></span></li></ul></li></ul></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Exercise</a></span></li><li><span><a href=\"#Level-Up\" data-toc-modified-id=\"Level-Up-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Level Up</a></span><ul class=\"toc-item\"><li><span><a href=\"#More-Generalizations:-Other-Link-Functions,-Other-Models\" data-toc-modified-id=\"More-Generalizations:-Other-Link-Functions,-Other-Models-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>More Generalizations: Other Link Functions, Other Models</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For our modeling steps\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# For demonstrative purposes\n",
    "from scipy.special import logit, expit\n",
    "from sklearn import datasets\n",
    "\n",
    "# REVIEW: https://quantifyinghealth.com/interpret-logistic-regression-coefficients/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Explain the form of logistic regression\n",
    "- Explain how to interpret logistic regression coefficients\n",
    "- Use logistic regression to perform a classification task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cost Functions and Solutions To the Optimization Problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Unlike the least-squares problem for linear regression, no one has yet found a closed-form solution to the optimization problem presented by logistic regression. But even if one exists, the computation would no doubt be so complex that we'd be better off using some sort of approximation method instead."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But there's still a problem.\n",
    "\n",
    "Recall the cost function for linear regression: <br/><br/>\n",
    "$SSE = \\Sigma_i(y_i - \\hat{y}_i)^2 = \\Sigma_i(y_i - (\\beta_0 + \\beta_1x_{i1} + ... + \\beta_nx_{in}))^2$.\n",
    "\n",
    "This function, $SSE(\\vec{\\beta})$, is convex.\n",
    "\n",
    "If we plug in our new logistic equation for $\\hat{y}$, we get: <br/><br/>\n",
    "$SSE_{log} = \\Sigma_i(y_i - \\hat{y}_i)^2 = \\Sigma_i\\left(y_i - \\left(\\frac{1}{1+e^{-(\\beta_0 + \\beta_1x_{i1} + ... + \\beta_nx_{in})}}\\right)\\right)^2$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## The Bad News"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*This* function, $SSE_{log}(\\vec{\\beta})$, is [**not** convex](https://towardsdatascience.com/why-not-mse-as-a-loss-function-for-logistic-regression-589816b5e03c).\n",
    "\n",
    "That means that, if we tried to use gradient descent or some other approximation method that looks for the minimum of this function, we could easily find a local rather than a global minimum."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Note that the scikit-learn class *expects the user to specify the solver* to be used in calculating the coefficients. The default solver, [lbfgs](https://en.wikipedia.org/wiki/Limited-memory_BFGS), works well for many applications."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## The Good News"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can use **log-loss** instead:\n",
    "\n",
    "$\\mathcal{L}(\\vec{y}, \\hat{\\vec{y}}) = -\\frac{1}{N}\\Sigma^N_{i=1}\\left(y_iln(\\hat{y}_i)+(1-y_i)ln(1-\\hat{y}_i)\\right)$,\n",
    "\n",
    "where $\\hat{y}_i$ is the probability that $(x_{i1}, ... , x_{in})$ belongs to **class 1**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**More resources on the log-loss function**:\n",
    "\n",
    "https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-ii-d20a239cde11\n",
    "\n",
    "https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ðŸ§  Knowledge Check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Is a bigger value (more positive) better or worse than a smaller value?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- What would the log-loss for one data point when the target is $0$ but we predict $1$?\n",
    "\n",
    "- What would the log-loss for one data point when the target is $0$ but we predict $0$?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### More Log-Loss Resources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Digging Deeper into Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.52320</td>\n",
       "      <td>13.72</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>71.75</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ri     na    mg    al     si     k     ca   ba    fe  glass_type\n",
       "id                                                                        \n",
       "22   1.51966  14.77  3.75  0.29  72.02  0.03   9.00  0.0  0.00           1\n",
       "185  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.0  0.00           6\n",
       "40   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1\n",
       "39   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1\n",
       "51   1.52320  13.72  3.72  0.51  71.75  0.09  10.06  0.0  0.16           1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glass identification dataset\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data'\n",
    "col_names = ['id','ri','na','mg','al','si','k','ca','ba','fe','glass_type']\n",
    "glass = pd.read_csv(url, names=col_names, index_col='id')\n",
    "glass.sort_values('al', inplace=True)\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "      <th>household</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.52320</td>\n",
       "      <td>13.72</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>71.75</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ri     na    mg    al     si     k     ca   ba    fe  glass_type  \\\n",
       "id                                                                           \n",
       "22   1.51966  14.77  3.75  0.29  72.02  0.03   9.00  0.0  0.00           1   \n",
       "185  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.0  0.00           6   \n",
       "40   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "39   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "51   1.52320  13.72  3.72  0.51  71.75  0.09  10.06  0.0  0.16           1   \n",
       "\n",
       "     household  \n",
       "id              \n",
       "22           0  \n",
       "185          1  \n",
       "40           0  \n",
       "39           0  \n",
       "51           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# types 1, 2, 3 are window glass\n",
    "# types 5, 6, 7 are household glass\n",
    "glass['household'] = glass.glass_type.map({1:0, 2:0, 3:0, 5:1, 6:1, 7:1})\n",
    "glass.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fit a logistic regression model and store the class predictions\n",
    "\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "feature_cols = ['al']\n",
    "X = glass[feature_cols]\n",
    "y = glass.household\n",
    "logreg.fit(X, y)\n",
    "glass['household_pred_class'] = logreg.predict(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36150680872607704"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y, logreg.predict_proba(X))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying by Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = logreg.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36150680872607704"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.mean([y*np.log(y_hat) + (1-y)*np.log(1-y_hat)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Interpreting Logistic Regression Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.11517927]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How do we interpret the coefficients of a logistic regression? For a linear regression, the situaton was like this:\n",
    "\n",
    "- Linear Regression: We construct the best-fit line and get a set of coefficients. Suppose $\\beta_1 = k$. In that case we would expect a 1-unit change in $x_1$ to produce a $k$-unit change in $y$.\n",
    "\n",
    "- Logistic Regression: We find the coefficients of the best-fit line by some approximation method. Suppose $\\beta_1 = k$. In that case we would expect a 1-unit change in $x_1$ to produce a $k$-unit change (not in $y$ but) in $ln\\left(\\frac{y}{1-y}\\right)$.\n",
    "\n",
    "We have:\n",
    "\n",
    "$\\ln\\left(\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)}\\right) = \\ln\\left(\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}\\right) + k$.\n",
    "\n",
    "Exponentiating both sides:\n",
    "\n",
    "$\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)} = e^{\\ln\\left(\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}\\right) + k}$ <br/><br/> $\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)}= e^{\\ln\\left(\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}\\right)}\\cdot e^k$ <br/><br/> $\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)}= e^k\\cdot\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}$\n",
    "\n",
    "That is, the odds ratio at $x_1+1$ has increased by a factor of $e^k$ relative to the odds ratio at $x_1$.\n",
    "\n",
    "For more on interpretation, see [this page](https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/how-to/binary-logistic-regression/interpret-the-results/all-statistics-and-graphs/coefficients/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.00934605])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the intercept\n",
    "\n",
    "logreg.intercept_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Interpretation:** For an 'al' value of 0, the log-odds of 'household' is -6.01. What is the probability that glass with an 'al' value of 0 is household glass?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00244968])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert log-odds to probability\n",
    "\n",
    "#  make sure you standard scale if you want to do default regularization\n",
    "\n",
    "logodds = logreg.intercept_\n",
    "odds = np.exp(logodds)\n",
    "prob = odds / (1 + odds)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('al', 3.1151792681570174)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the coefficient for al\n",
    "\n",
    "list(zip(feature_cols, logreg.coef_[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Interpretation:** A 1 unit increase in 'al' is associated with a 3.12-unit increase in the log-odds of 'household'."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Aside: Verifying log-odds to probability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's verify this as we change the aluminum content from 1 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/llakes/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.94755733, 0.05244267]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction for al=1\n",
    "\n",
    "pred_al1 = logreg.predict_proba([[1]])\n",
    "pred_al1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05534512023573519"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Odds ratio for al=1\n",
    "\n",
    "odds_al1 = pred_al1[0][1] / pred_al1[0][0]\n",
    "odds_al1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/llakes/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4449707, 0.5550293]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction for al=2\n",
    "pred_al2 = logreg.predict_proba([[2]])\n",
    "pred_al2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2473390003597828"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Odds ratio for al=2\n",
    "\n",
    "odds_al2 = pred_al2[0][1] / pred_al2[0][0]\n",
    "odds_al2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2473390003597822\n",
      "1.2473390003597828\n"
     ]
    }
   ],
   "source": [
    "print((np.exp(logreg.coef_[0]) * odds_al1)[0])\n",
    "print(odds_al2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Aside: Use Coefficients to Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22101248])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute predicted log-odds for al=2 using the equation\n",
    "x_al = 2\n",
    "logodds = logreg.intercept_ + logreg.coef_[0] * x_al\n",
    "logodds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.247339])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert log-odds to odds\n",
    "\n",
    "odds = np.exp(logodds)\n",
    "odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5550293])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert odds to probability\n",
    "\n",
    "prob = odds / (1 + odds)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/llakes/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5550293])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute predicted probability for al=2 using the predict_proba method\n",
    "\n",
    "logreg.predict_proba(np.array([2.0]).reshape(1, 1))[:, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Putting It All Together: Training Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take some time to show how you can do use logistic regression in practice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Note we've been talking about _binary classification_ but we can also do classification for _multiclass_ problems (more than binary classes).\n",
    ">\n",
    "> That's what we'll do for this example."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Built in dataset from sklearn\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=np.c_[iris['data'], iris['target']],\n",
    "    columns=iris['feature_names'] + ['target']\n",
    ")\n",
    "\n",
    "display(df.head())\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note how many different targets there are\n",
    "df.target.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can go ahead and explore some graphs to show that it doesn't make sense to do a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a large figure\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Iterating over the different\n",
    "for i in range(0, 4):\n",
    "    # Figure number starts at 1\n",
    "    ax = fig.add_subplot(2, 2, i+1)\n",
    "    # Add a title to make it clear what each subplot shows\n",
    "    plt.title(df.columns[i])\n",
    "    # Use alpha to better see crossing pints\n",
    "    ax.scatter(df['target'], df.iloc[:, i], c='teal', alpha=0.1)\n",
    "    # Only show the tick marks for each target\n",
    "    plt.xticks(df.target.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Preparing the data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get the features and then the target\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80377277, 0.55160877, 0.22064351, 0.0315205 ],\n",
       "       [0.82813287, 0.50702013, 0.23660939, 0.03380134],\n",
       "       [0.80533308, 0.54831188, 0.2227517 , 0.03426949],\n",
       "       [0.80003025, 0.53915082, 0.26087943, 0.03478392],\n",
       "       [0.790965  , 0.5694948 , 0.2214702 , 0.0316386 ],\n",
       "       [0.78417499, 0.5663486 , 0.2468699 , 0.05808704],\n",
       "       [0.78010936, 0.57660257, 0.23742459, 0.0508767 ],\n",
       "       [0.80218492, 0.54548574, 0.24065548, 0.0320874 ],\n",
       "       [0.80642366, 0.5315065 , 0.25658935, 0.03665562],\n",
       "       [0.81803119, 0.51752994, 0.25041771, 0.01669451],\n",
       "       [0.80373519, 0.55070744, 0.22325977, 0.02976797],\n",
       "       [0.786991  , 0.55745196, 0.26233033, 0.03279129],\n",
       "       [0.82307218, 0.51442011, 0.24006272, 0.01714734],\n",
       "       [0.8025126 , 0.55989251, 0.20529392, 0.01866308],\n",
       "       [0.81120865, 0.55945424, 0.16783627, 0.02797271],\n",
       "       [0.77381111, 0.59732787, 0.2036345 , 0.05430253],\n",
       "       [0.79428944, 0.57365349, 0.19121783, 0.05883625],\n",
       "       [0.80327412, 0.55126656, 0.22050662, 0.04725142],\n",
       "       [0.8068282 , 0.53788547, 0.24063297, 0.04246464],\n",
       "       [0.77964883, 0.58091482, 0.22930848, 0.0458617 ],\n",
       "       [0.8173379 , 0.51462016, 0.25731008, 0.03027177],\n",
       "       [0.78591858, 0.57017622, 0.23115252, 0.06164067],\n",
       "       [0.77577075, 0.60712493, 0.16864581, 0.03372916],\n",
       "       [0.80597792, 0.52151512, 0.26865931, 0.07901744],\n",
       "       [0.776114  , 0.54974742, 0.30721179, 0.03233808],\n",
       "       [0.82647451, 0.4958847 , 0.26447184, 0.03305898],\n",
       "       [0.79778206, 0.5424918 , 0.25529026, 0.06382256],\n",
       "       [0.80641965, 0.54278246, 0.23262105, 0.03101614],\n",
       "       [0.81609427, 0.5336001 , 0.21971769, 0.03138824],\n",
       "       [0.79524064, 0.54144043, 0.27072022, 0.03384003],\n",
       "       [0.80846584, 0.52213419, 0.26948861, 0.03368608],\n",
       "       [0.82225028, 0.51771314, 0.22840286, 0.06090743],\n",
       "       [0.76578311, 0.60379053, 0.22089897, 0.0147266 ],\n",
       "       [0.77867447, 0.59462414, 0.19820805, 0.02831544],\n",
       "       [0.81768942, 0.51731371, 0.25031309, 0.03337508],\n",
       "       [0.82512295, 0.52807869, 0.19802951, 0.03300492],\n",
       "       [0.82699754, 0.52627116, 0.19547215, 0.03007264],\n",
       "       [0.78523221, 0.5769053 , 0.22435206, 0.01602515],\n",
       "       [0.80212413, 0.54690282, 0.23699122, 0.03646019],\n",
       "       [0.80779568, 0.53853046, 0.23758697, 0.03167826],\n",
       "       [0.80033301, 0.56023311, 0.20808658, 0.04801998],\n",
       "       [0.86093857, 0.44003527, 0.24871559, 0.0573959 ],\n",
       "       [0.78609038, 0.57170209, 0.23225397, 0.03573138],\n",
       "       [0.78889479, 0.55222635, 0.25244633, 0.09466737],\n",
       "       [0.76693897, 0.57144472, 0.28572236, 0.06015208],\n",
       "       [0.82210585, 0.51381615, 0.23978087, 0.05138162],\n",
       "       [0.77729093, 0.57915795, 0.24385598, 0.030482  ],\n",
       "       [0.79594782, 0.55370283, 0.24224499, 0.03460643],\n",
       "       [0.79837025, 0.55735281, 0.22595384, 0.03012718],\n",
       "       [0.81228363, 0.5361072 , 0.22743942, 0.03249135],\n",
       "       [0.76701103, 0.35063361, 0.51499312, 0.15340221],\n",
       "       [0.74549757, 0.37274878, 0.52417798, 0.17472599],\n",
       "       [0.75519285, 0.33928954, 0.53629637, 0.16417236],\n",
       "       [0.75384916, 0.31524601, 0.54825394, 0.17818253],\n",
       "       [0.7581754 , 0.32659863, 0.5365549 , 0.17496355],\n",
       "       [0.72232962, 0.35482858, 0.57026022, 0.16474184],\n",
       "       [0.72634846, 0.38046824, 0.54187901, 0.18446945],\n",
       "       [0.75916547, 0.37183615, 0.51127471, 0.15493173],\n",
       "       [0.76301853, 0.33526572, 0.53180079, 0.15029153],\n",
       "       [0.72460233, 0.37623583, 0.54345175, 0.19508524],\n",
       "       [0.76923077, 0.30769231, 0.53846154, 0.15384615],\n",
       "       [0.73923462, 0.37588201, 0.52623481, 0.187941  ],\n",
       "       [0.78892752, 0.28927343, 0.52595168, 0.13148792],\n",
       "       [0.73081412, 0.34743622, 0.56308629, 0.16772783],\n",
       "       [0.75911707, 0.3931142 , 0.48800383, 0.17622361],\n",
       "       [0.76945444, 0.35601624, 0.50531337, 0.16078153],\n",
       "       [0.70631892, 0.37838513, 0.5675777 , 0.18919257],\n",
       "       [0.75676497, 0.35228714, 0.53495455, 0.13047672],\n",
       "       [0.76444238, 0.27125375, 0.55483721, 0.18494574],\n",
       "       [0.76185188, 0.34011245, 0.53057542, 0.14964948],\n",
       "       [0.6985796 , 0.37889063, 0.56833595, 0.21312598],\n",
       "       [0.77011854, 0.35349703, 0.50499576, 0.16412362],\n",
       "       [0.74143307, 0.29421947, 0.57667016, 0.17653168],\n",
       "       [0.73659895, 0.33811099, 0.56754345, 0.14490471],\n",
       "       [0.76741698, 0.34773582, 0.51560829, 0.15588157],\n",
       "       [0.76785726, 0.34902603, 0.51190484, 0.16287881],\n",
       "       [0.76467269, 0.31486523, 0.53976896, 0.15743261],\n",
       "       [0.74088576, 0.33173989, 0.55289982, 0.18798594],\n",
       "       [0.73350949, 0.35452959, 0.55013212, 0.18337737],\n",
       "       [0.78667474, 0.35883409, 0.48304589, 0.13801311],\n",
       "       [0.76521855, 0.33391355, 0.52869645, 0.15304371],\n",
       "       [0.77242925, 0.33706004, 0.51963422, 0.14044168],\n",
       "       [0.76434981, 0.35581802, 0.51395936, 0.15814134],\n",
       "       [0.70779525, 0.31850786, 0.60162596, 0.1887454 ],\n",
       "       [0.69333409, 0.38518561, 0.57777841, 0.1925928 ],\n",
       "       [0.71524936, 0.40530797, 0.53643702, 0.19073316],\n",
       "       [0.75457341, 0.34913098, 0.52932761, 0.16893434],\n",
       "       [0.77530021, 0.28304611, 0.54147951, 0.15998258],\n",
       "       [0.72992443, 0.39103094, 0.53440896, 0.16944674],\n",
       "       [0.74714194, 0.33960997, 0.54337595, 0.17659719],\n",
       "       [0.72337118, 0.34195729, 0.57869695, 0.15782644],\n",
       "       [0.73260391, 0.36029701, 0.55245541, 0.1681386 ],\n",
       "       [0.76262994, 0.34186859, 0.52595168, 0.1577855 ],\n",
       "       [0.76986879, 0.35413965, 0.5081134 , 0.15397376],\n",
       "       [0.73544284, 0.35458851, 0.55158213, 0.1707278 ],\n",
       "       [0.73239618, 0.38547167, 0.53966034, 0.15418867],\n",
       "       [0.73446047, 0.37367287, 0.5411814 , 0.16750853],\n",
       "       [0.75728103, 0.3542121 , 0.52521104, 0.15878473],\n",
       "       [0.78258054, 0.38361791, 0.4603415 , 0.16879188],\n",
       "       [0.7431482 , 0.36505526, 0.5345452 , 0.16948994],\n",
       "       [0.65387747, 0.34250725, 0.62274045, 0.25947519],\n",
       "       [0.69052512, 0.32145135, 0.60718588, 0.22620651],\n",
       "       [0.71491405, 0.30207636, 0.59408351, 0.21145345],\n",
       "       [0.69276796, 0.31889319, 0.61579374, 0.1979337 ],\n",
       "       [0.68619022, 0.31670318, 0.61229281, 0.232249  ],\n",
       "       [0.70953708, 0.28008043, 0.61617694, 0.1960563 ],\n",
       "       [0.67054118, 0.34211284, 0.61580312, 0.23263673],\n",
       "       [0.71366557, 0.28351098, 0.61590317, 0.17597233],\n",
       "       [0.71414125, 0.26647062, 0.61821183, 0.19185884],\n",
       "       [0.69198788, 0.34599394, 0.58626751, 0.24027357],\n",
       "       [0.71562645, 0.3523084 , 0.56149152, 0.22019275],\n",
       "       [0.71576546, 0.30196356, 0.59274328, 0.21249287],\n",
       "       [0.71718148, 0.31640359, 0.58007326, 0.22148252],\n",
       "       [0.6925518 , 0.30375079, 0.60750157, 0.24300063],\n",
       "       [0.67767924, 0.32715549, 0.59589036, 0.28041899],\n",
       "       [0.69589887, 0.34794944, 0.57629125, 0.25008866],\n",
       "       [0.70610474, 0.3258945 , 0.59747324, 0.1955367 ],\n",
       "       [0.69299099, 0.34199555, 0.60299216, 0.19799743],\n",
       "       [0.70600618, 0.2383917 , 0.63265489, 0.21088496],\n",
       "       [0.72712585, 0.26661281, 0.60593821, 0.18178146],\n",
       "       [0.70558934, 0.32722984, 0.58287815, 0.23519645],\n",
       "       [0.68307923, 0.34153961, 0.59769433, 0.24395687],\n",
       "       [0.71486543, 0.25995106, 0.62202576, 0.18567933],\n",
       "       [0.73122464, 0.31338199, 0.56873028, 0.20892133],\n",
       "       [0.69595601, 0.3427843 , 0.59208198, 0.21813547],\n",
       "       [0.71529453, 0.31790868, 0.59607878, 0.17882363],\n",
       "       [0.72785195, 0.32870733, 0.56349829, 0.21131186],\n",
       "       [0.71171214, 0.35002236, 0.57170319, 0.21001342],\n",
       "       [0.69594002, 0.30447376, 0.60894751, 0.22835532],\n",
       "       [0.73089855, 0.30454106, 0.58877939, 0.1624219 ],\n",
       "       [0.72766159, 0.27533141, 0.59982915, 0.18683203],\n",
       "       [0.71578999, 0.34430405, 0.5798805 , 0.18121266],\n",
       "       [0.69417747, 0.30370264, 0.60740528, 0.2386235 ],\n",
       "       [0.72366005, 0.32162669, 0.58582004, 0.17230001],\n",
       "       [0.69385414, 0.29574111, 0.63698085, 0.15924521],\n",
       "       [0.73154399, 0.28501714, 0.57953485, 0.21851314],\n",
       "       [0.67017484, 0.36168166, 0.59571097, 0.2553047 ],\n",
       "       [0.69804799, 0.338117  , 0.59988499, 0.196326  ],\n",
       "       [0.71066905, 0.35533453, 0.56853524, 0.21320072],\n",
       "       [0.72415258, 0.32534391, 0.56672811, 0.22039426],\n",
       "       [0.69997037, 0.32386689, 0.58504986, 0.25073566],\n",
       "       [0.73337886, 0.32948905, 0.54206264, 0.24445962],\n",
       "       [0.69052512, 0.32145135, 0.60718588, 0.22620651],\n",
       "       [0.69193502, 0.32561648, 0.60035539, 0.23403685],\n",
       "       [0.68914871, 0.33943145, 0.58629069, 0.25714504],\n",
       "       [0.72155725, 0.32308533, 0.56001458, 0.24769876],\n",
       "       [0.72965359, 0.28954508, 0.57909015, 0.22005426],\n",
       "       [0.71653899, 0.3307103 , 0.57323119, 0.22047353],\n",
       "       [0.67467072, 0.36998072, 0.58761643, 0.25028107],\n",
       "       [0.69025916, 0.35097923, 0.5966647 , 0.21058754]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the data to help the model\n",
    "X = normalize(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now each row vector has unit length\n",
    "sum([x**2 for x in X[0, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split for test & training  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Create and Train Logistic Regression Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There's a lot of different parameters for `LogisticRegression`. Check out the documentation for more info: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_model = LogisticRegression(\n",
    "            C=1e3,             # Smaller values -> more regularization\n",
    "            max_iter=1e3,      # Ensure we eventually reach a solution\n",
    "            solver='lbfgs',    # (Default) Can optimize depending on problem\n",
    "            multi_class='ovr'  # (Default) Will try to do multiclass classification \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'max_iter' parameter of LogisticRegression must be an int in the range [0, inf). Got 1000.0 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8a19b51f766f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit/Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \"\"\"\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0maccepted\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \"\"\"\n\u001b[0;32m--> 600\u001b[0;31m         validate_parameter_constraints(\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 )\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             raise InvalidParameterError(\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0;34mf\"The {param_name!r} parameter of {caller_name} must be\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;34mf\" {constraints_str}. Got {param_val!r} instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'max_iter' parameter of LogisticRegression must be an int in the range [0, inf). Got 1000.0 instead."
     ]
    }
   ],
   "source": [
    "# Fit/Train the model\n",
    "my_model.fit(X_train, y_train)\n",
    "my_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Optional: Evaluate the Model with Cross-Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In practice, we should make this a practice but we skip it if time is running low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "                    estimator=my_model,\n",
    "                    X=X_train,\n",
    "                    y=y_train,\n",
    "                    cv=5,\n",
    "                    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv_results['train_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv_results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cv_overall(cv_results):\n",
    "    val_results = cv_results['test_score']\n",
    "    result_str = f'{val_results.mean():.3f} Â± {val_results.std():.3f}'\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv_overall(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's save these results for later\n",
    "models = {}\n",
    "\n",
    "models['model_1'] = {'model': my_model, 'cv':cv_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Overall Training Score\n",
    "my_model.score(X_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Optional: Rinse and Repeat - Multiple Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try out a few more models for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Adjust the regularization C\n",
    "c_values = [1e-1, 1e2, 1e4, 1e6]\n",
    "\n",
    "# Start at #2 since we have \"model_1\" already\n",
    "for i, c in enumerate(c_values, start=2):\n",
    "    \n",
    "    print(f'Model #{i} with C={c}')\n",
    "    new_model = LogisticRegression(C=c, max_iter=1e3)\n",
    "    \n",
    "    # Cross-validation\n",
    "    print('Cross-validating model with training data...')\n",
    "    cv_results = cross_validate(\n",
    "                    estimator=new_model,\n",
    "                    X=X_train,\n",
    "                    y=y_train,\n",
    "                    cv=5,\n",
    "                    return_train_score=True\n",
    "    )\n",
    "    print(f'\\tCross-Validation Score: {cv_overall(cv_results)}')\n",
    "    \n",
    "    # Train/fit with the full training set\n",
    "    print('Fitting model to full training set...')\n",
    "    new_model.fit(X_train, y_train)\n",
    "    train_score = new_model.score(X_train, y_train)\n",
    "    print(f'\\tScore on training set: {train_score:.3f}')\n",
    "    \n",
    "    # Save results\n",
    "    print('Saving Results...')\n",
    "    models[f'model_{i}'] = {'model': new_model, 'cv': cv_results}\n",
    "    \n",
    "    print('\\n','-'*30,'\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_model = models['model_5']['model']\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's get predictions for training & testing sets\n",
    "y_hat_train = best_model.predict(X_train)\n",
    "y_hat_test = best_model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Loss on Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_loss(y_train, best_model.predict_proba(X_train)))\n",
    "print(log_loss(y_test, best_model.predict_proba(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Was our model correct?\n",
    "residuals = y_train == y_hat_train\n",
    "\n",
    "print('Number of values correctly predicted:')\n",
    "print(pd.Series(residuals).value_counts())\n",
    "\n",
    "print('\\n','-'*30,'\\n')\n",
    "\n",
    "print('Percentage of values correctly predicted: ')\n",
    "print(pd.Series(residuals).value_counts(normalize=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "residuals = y_test == y_hat_test\n",
    "\n",
    "print('Number of values correctly predicted:')\n",
    "print(pd.Series(residuals).value_counts())\n",
    "\n",
    "print('\\n','-'*30,'\\n')\n",
    "\n",
    "print('Percentage of values correctly predicted: ')\n",
    "print(pd.Series(residuals).value_counts(normalize=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Split the data below into train and test, and then convert the y-values (`geysers.kind`) into 1's and 0's. Then use `sklearn` to build a logistic regression model of whether Old Faithful's eruption wait time is long or short, based on the duration of the eruption. Finally, find the points in the test set where the model's prediction differs from the true y-value. How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "geysers = sns.load_dataset('geyser', **{'usecols': ['duration', 'kind']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "geysers.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## More Generalizations: Other Link Functions, Other Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Logistic regression's link function is the logit function, but different sorts of models use different link functions.\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function) has a nice table of generalized linear model types and their associated link functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
